
\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%

\usepackage{alltt}
\usepackage{enumerate}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{xargs}
\usepackage{amssymb}
\usepackage{amsmath}

\renewcommand{\CommentSty}[1]{\textnormal{#1}}
\DontPrintSemicolon
\SetKwComment{tcp}{$\triangleright$ }{}
\SetVlineSkip{0cm}
\SetAlgoSkip{}

\let\oldemptyset\emptyset
\let\emptyset\varnothing

\DeclareMathOperator{\dist}{dist}


% Insert the name of "your journal" with
\journalname{VLDBJ}
%
\begin{document}

\title{Adaptive Disk Storage for Interaction Graphs}

%\titlerunning{Short form of title}        % if too long for running head

\author{Robert Soul\'{e}         \and
        Bu\u{g}ra Gedik%etc.
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{B. Gedik \at            
              \email{bgedik@cs.bilkent.edu.tr}           %  \\
           \and
           R. Soul\'{e} \at
               \email{robert.soule@usi.ch}     
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
Insert your abstract here. Include keywords, PACS and mathematical
subject classification numbers as needed.
\keywords{First keyword \and Second keyword \and More}
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}



\section{Introduction}
An \emph{interaction graph} is an append-only graph, where new edges and
vertices are added as time progresses.%

Typical interaction graphs have data associated with their vertices and edges.
We call this data \emph{attributes} or \emph{properties}. Most algorithms
access this data as they traverse the graph. However, not all of the data is
accessed by all the queries. Typically, there are correlations among the
attributes accessed by different queries, such as Q1 and Q5 accessing
attributes a and b, and Q2, Q3, Q4 accessing attributes c and d, and so on.%

In an interaction graph database organized as blocks of temporal neighborlists
(as in Gedik et al.~\cite{gedik14}), it is important to store the edge and
vertex properties locally. For  instance, if the edge properties are kept away
in a relational table, there will be almost no benefit to the locality
optimizations performed for block organization (discussed in Gedik et
al.~\cite{gedik14}, as we would have to go back and forth between the disk
blocks to access the edge attributes).%

On the other hand, putting all the edge attributes into the disk blocks
containing the graph structure is expected to cause significant overhead when
only a few of these attributes are read. This is somewhat similar to the 
problem with row-oriented databases, where the entire row needs to be accessed
from the disk despite the query needing only a small fraction of it.
Unfortunately, there is no clear correspondence to a column-oriented database
layout for the graph databases.%

An important characteristic of interaction graphs are that they are temporal.
As such, the co-access correlations for the attributes can be different for
different temporal regions. It might also be unknown at the insertion time and
may be discovered later depending on the workload. This points to the need for
adaptively optimizing the layout (somewhat similar to H2O \cite{alagiannis14}
and HYRISE~\cite{grund10}).%

I imagine a solution to this problem, which I name the `rail layout'. The idea
is to start with large blocks that contain the entire data. As we learn about
the access properties for different time regions, we might start splitting
such blocks into smaller blocks that run parallel to each other, almost like
having two or more graph databases for certain time regions, each containing a
 different subset of the attributes, but with a link between them in case a
query needs to access both.

\section{Problem Description}

The problem is to determine a partitioning of the disk blocks into sub-blocks
that would minimize query I/O. Of course, partitioning into sub-blocks results
in an increase in storage cost. The storage cost must stay below some
specified limit.

There are two possibilities: \emph{overlapping} and \emph{non-overlapping}
partitioning. In the overlapping case, attributes can be replicated in the
sub-blocks. The non-overlapping case is a true partition.

We start by defining the cost model, which formalizes the query I/O and storage
costs.

\section{Cost Model}
Let $Q$ be the query workload, where each query $q\in Q$ accesses a set of
attributes $q.A$ and traverses parts of the graph for the time range
$q.T=[q.t_s,q.t_e]$. We denote the set of all attributes as $A$. Given a block
$B$, we denote its time range as $B.T$, which is the union of the time ranges
of its temporal neighborlists. Let $s(a)$ denote the size of an attribute $a$.
We use $c_n(B)$ to denote the number of temporal neighborlists within block
$B$ and $c_e(B)$ to denote the total number of edges in the temporal
neighborlists within the block. We overload the notation for block size and
use $s(B)$ to denote the size of a block $B$. We have: 
\begin{equation}
s(B) = c_e(B) \cdot \left(16 + \sum_{a\in B.A} s(a)\right) + c_n(B) \cdot 12  
\end{equation}
Here, $16$ corresponds to the cost of storing the edge id and the timestamp,
and $12$ corresponds to the cost of storing the head vertex ($8$ bytes) plus
the number of entries ($4$ bytes) for a temporal neighborlist. 

Our goal is to create a potentially overlapping partitioning of a block,
denoted by $\mathcal{P}(B)$. We call the partitions \emph{sub-blocks}. We have
$\bigcup_{B'\in \mathcal{P}(B)} B'.A = A$. We aim to find the function
$\mathcal{P}$ that minimizes the query I/O over $B$, while keeping the
relative storage overhead beyond a limit, say $1+\alpha$ times the original.
If we represent the query I/O as $L(\mathcal{P}, B)$ and the relative storage
overhead as $H(\mathcal{P}, B)$, our goal is to find:
\begin{equation}
\mathcal{P} \leftarrow \mbox{argmin}_{\{\mathcal{P}: H(\mathcal{P}(B)) < \alpha\}} L(\mathcal{P},B)
\end{equation}

The storage overhead can be formalized as:
\begin{equation}
H(\mathcal{P}, B) = (|\mathcal{P}(B)|-1)\cdot\left(1-\frac{c_e(B)\cdot \sum_{a\in A} s(a)}{s(B)}\right) 
\end{equation}

\subsection{Query I/O}

Let $m$ be a function that maps a query $q$ to the set of sub-blocks that are
accessed to satisfy it for a relevant block $B$ under a given partitioning
$\mathcal{P}$. For the case of non-overlapping attributes, we have:
\begin{equation}
m(\mathcal{P}, B, q) = \{B': B'\in \mathcal{P}(B) \wedge q.A \cap B'.A \ne \emptyset\}  
\end{equation}

For the case of overlapping attributes, we use a simple heuristic to define the
set of sub-blocks to be used for answering the query.
Algorithm~\ref{alg:greedyM} captures it. The idea is to select sub-blocks that
bring the highest relative marginal gain, which is defined as the size of
attribute data that contributes to the query result, relative to the sub-block
size. While computing the marginal gain, attributes that are covered by
sub-blocks that are already selected are not considered.
%
\begin{algorithm}[h]
\scriptsize
\caption{m-overlapping($\mathcal{P}, B, q$)}
\label{alg:greedyM}
\KwData{$\mathcal{P}$: partitioning function, $B$: block, $q$: query}
$S\leftarrow \emptyset; R\leftarrow \emptyset$ \tcp*{Selected attributes; Resulting sub-blocks}
\While(\tcp*[f]{While unselected attributes remain}){$S \subset q.A$}{
  $B' \leftarrow \mbox{argmax}_{B'\in\mathcal{P}(B)\setminus R} \sum_{a\in B'.A \cap q.A \setminus S} \frac{c_e(B') \cdot s(a)}{s(B')}$
  $S \leftarrow S \cup B'.A$\tcp*{Extend the selected attributes}
  $R\leftarrow R \cup B'$\tcp*{Extend the selected sub-blocks}
}
\Return R \tcp*{Final set of sub-blocks covering the query attributes}
\end{algorithm} 
%
The query I/O cost for a block is then given by:
\begin{equation}
L(\mathcal{P}, B) = \sum_{q\in Q} \mathbf{1}(q.T \cap B.T \neq \emptyset) \cdot \sum_{B'\in m(\mathcal{P}, B, q)} \!\!s(B')
\end{equation}


\paragraph{\textbf{Other useful equations}}

\noindent The following are unused, but may be needed for the partitioning
algorithm.

Let $f: \mathbb{R}\times A \rightarrow \mathbb{N}$ be a function that maps a
attribute-timestamp pair $(a, t)$ to the frequency of queries that access
attribute $a$ for time $t$. More formally:
\begin{equation}
f(a,t) = \sum_{q\in Q} \textbf{1}(a\in q.A \wedge t\in q.T)
\end{equation}
 
Let $T$ represent a time range $[T.s, T.e]$. We denote the frequency of
attribute access for the time interval $T$ for attribute $a$ as follows:
\begin{equation}
f(a, T) = \int_{T.s}^{T.e} f(a, t)\cdot dt =  \sum_{q\in Q} |q.T \cap T| 
\end{equation}



\section{Partitioning}

TODO: This section is still a work-in-progress. We are trying to find the algorithms.


\subsection{Non-Overlapping Attributes}

\paragraph*{Problem.}\emph{Find a true partitioning of attributes that minimizes
  the query I/O and bounds the storage cost by some upper limit.}

%$\mathcal{P}(B) \leftarrow \emptyset$ \tcp*{Initial partitioning}

\begin{algorithm}[h]
\scriptsize
\caption{Algorithm for partitioning blocks into sub-blocks with non-overlapping attributes.}
\label{alg:overlappingP}
\KwData{$B$: block, $Q$: set of queries}
$c^*\leftarrow \infty$ \tcp*{Lowest cost over all \# of partitions}
\For(\tcp*[f]{For each possible \# of partitions}){$k=1$ to $|A|$}{
   $R[i]\leftarrow \emptyset, \forall i\in [1..k]$ \tcp*{Initialize partitions}
   \For(\tcp*[f]{For each attribute}){$a \in A$\textnormal{, in decr.\/ order of }$f(a)$}{
      $c\leftarrow \infty$ \tcp*{Lowest cost over all assignments}  
      $j\leftarrow -1$ \tcp*{Best partition assignment}
      \For(\tcp*[f]{For each partition assignment}){$i\in [1..k]$} {
         $R[i]\leftarrow R[i] \cup \{a\}$\tcp*{Assign attribute}
         \If(\tcp*[f]{If size is not feasable}){$H(R, B, Q)\geq\alpha$}{
            \textbf{continue}
         }
         \If(\tcp*[f]{If query cost is lower}){$L(R, B, Q)<c$}{
            $c\leftarrow L(R, B, Q)$\tcp*{Update the lowest cost}
            $j\leftarrow i$\tcp*{Update the best partition}
         }
         $R[i]\leftarrow R[i] \setminus \{a\}$\tcp*{Un-assign attribute}
      }
      $R[j]\leftarrow R[j] \cup \{a\}$\tcp*{Assign to best partition}
   }
   \If(\tcp*[f]{Has lower cost}){$||R||=|A| \wedge L(R, B, Q)<c^*$}{
      $c^* \leftarrow L(R, B, Q)$\tcp*{Update the lowest cost}
      $\mathcal{P}(B)\leftarrow R$\tcp*{Update the best partitioning}
   }
}
\Return $\mathcal{P}(B)$ \tcp*{Final set of sub-blocks}
\end{algorithm} 

\subsection{Mixed Integer Linear Program Formulation}
$x_{a,p}$: $1$ if attribute $a$ is in partition $p$, $0$ otherwise.\\
$y_{p,q}$: $1$ if partition $p$ is used by query $q$, $0$ otherwise.\\
$z_{a,p,q}$: $1$ if partition $p$ is used by query $q$, and attribute $a$ is in partition $p$, $0$ otherwise.\\

Let $q(a)\equiv \mathbf{1}(a \in q.A)$.

% NOTE: In the simulation we will have query weights that will factor into the objective function
\begin{eqnarray}
\text{minimize} 
    \Big(\sum_{q\in Q} \sum_{p=1}^{k} (16\cdot c_e(B) &+& 12\cdot c_n(B))\cdot y_{p,q}\nonumber\\
    + \sum_{a\in A} s(a)\cdot c_e(B)\cdot z_{a,p,q}\Big) &-& \Big(K\cdot \sum_{p=1}^{k} u_p + \sum_{q\in Q} y_{p,q}\Big) \nonumber\\
\text{subject to}\hspace{2.75cm}&&\nonumber\\
\forall_{a\in A}, 
    && \sum_{p=1}^{k} x_{a,p} = 1\nonumber\\
\forall_{\{p,q\}\in [1..k]\times Q}, 
    &&  \sum_{a\in A} q(a)\cdot x_{a,p} - y_{p,q} \geq 0 \nonumber\\
\forall_{\{a,p,q\}\in A\times [1..k]\times Q},
  && z_{a,p,q} - (x_{a,p} + y_{p,q}) \geq -1\nonumber\\
\end{eqnarray}

We will start with $k=|A|$ and check if the number of partitions used results
on the overhead constraint being satisified, that is:
$$\Big(1-\frac{c_e(B)\cdot \sum_{a\in A} s(a)}{s(B)}\Big) \cdot \Big(\sum_{p=1}^{k} u_p -1\Big) < \alpha$$

If the constraint is satisfied, then we are done. Otherwise, we set
$k=\sum_{p=1}^{k} u_p -1$ and repeat.

\subsection{Overlapping Attributes}

\paragraph*{Problem.}\emph{Find an overlapping partitioning of attributes that minimizes
  the query I/O and bounds the storage cost by some upper limit.}

\paragraph*{Approach.} We start the algorithm with a 
 partitioning based on what queries we have seen.
Every query gets its own sub-block. This is the``ideal'' partitioning,
because the I/O cost would be minimized for every query that we would
have seen. As input to the algorithm, we provide a function $\dist$, which
is used to compute the distance between two blocks.

$$
\dist: block \rightarrow block \rightarrow int
$$

Note that the $\dist$ function can be chosen arbitrarily.  Examples of useful
$\dist$ functions are the frequencies with which the queries are accessed, or the Jaccard index, which measures the set-similarity of
the attributes.

Using this function, the algorithm iteratively combines the two partitions that
are closest together. Algorithm~\ref{alg:closestBF} shows the pseudocode for a brute-force approach
  to finding the closest paris that runs in $O(n^2)$ time. However, there is
  also a divide-and-conquer algorithm~\cite{cormen01} for solving closest pair
  of points problem in $O(n \log n)$.
After each combination of partitions, the algorithm calculate the storage cost
for the partitioning. The algorithm stops when the  storage cost is below some
specified threshold.  The result is the block partitioning.



\begin{algorithm}[h]
\SetKwFunction{closestPair}{closestPair}
\scriptsize
\caption{Algorithm for partitioning blocks into sub-blocks with overlapping attributes.}
\label{alg:overlappingP}
\KwData{$B$: block, $Q$: set of queries}
$\mathcal{P}(B) \leftarrow \emptyset;$  \tcp*{Sub-blocks;}

\For(\tcp*[f]{Every query gets its own sub-block}){$q \in Q$}{ 
 $\mathcal{P}(B) = \mathcal{P}(B) \cup q.A$ 
}

\While(\tcp*[f]{While storage exceeds threshold}){$H(\mathcal{P}, B) \geq
  \text{max}$}{
$\text{x}, \text{y}  \leftarrow  \closestPair{}  $\;
 $ \mathcal{P}(B)  \leftarrow \mathcal{P}(B) - \{x, y\}$ \;
  $\mathcal{P}(B)  \leftarrow \mathcal{P}(B)  \cup \{ x \cup y \}$ \;
}
\Return $ \mathcal{P}(B)$  \tcp*{Final set of sub-blocks}
\end{algorithm} 



 \begin{algorithm}[h]
\SetKwFunction{length}{length}
\SetKwFunction{dist}{dist}
 \scriptsize
 \caption{Brute-force algorithm for closest points in $O(n^2)$.}
 \label{alg:closestBF}



$minDist  \gets \infty $ \;
\For{$i \gets 1$ \textbf{to} $\length(P)-1$} {
\For{$j \gets i+ 1$ \textbf{to} $\length(P)$} {

  $p \gets P[i]$ \;
  $q \gets P[j]$ \;
  \If{$\dist(p,q) < minDist$} {
    $minDist \gets \dist(p,q)$\;
    $closestPair \gets (p,q)$\;
  }
}
}
\Return $closestPair$

% \KwData{$B$: block, $Q$: set of queries}



% $\mathcal{P}(B) \leftarrow \emptyset;$  \tcp*{Sub-blocks;}

% \For(\tcp*[f]{Every query gets its own sub-block}){$q \in Q$}{ 
%  $\mathcal{P}(B) = \mathcal{P}(B) \cup q.A$ 
% }

% \While(\tcp*[f]{While storage exceeds threshold}){$H(\mathcal{P}, B) \geq
%   \text{max}$}{
% $\text{x}, \text{y}  \leftarrow  \closestPair{}  $\;
%  $ \mathcal{P}(B)  \leftarrow \mathcal{P}(B) - x - y$ \;
%   $\mathcal{P}(B)  \leftarrow \mathcal{P}(B)  + x \cup y$ \;

% \Return $ \mathcal{P}(B)$  \tcp*{Final set of sub-blocks}
 \end{algorithm} 


%\begin{acknowledgements}
%If you'd like to thank anyone, place your comments here
%and remove the percent signs.
%\end{acknowledgements}

\bibliographystyle{spmpsci}
\bibliography{main} 



\end{document}
% end of file template.tex

