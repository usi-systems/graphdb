\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{alltt}
\usepackage{balance}
\usepackage{url}


\begin{document}

% \begin{alltt}\scriptsize
%  Concise project description
% 2.1. Summary
% Max. one page
% 2.2. Project outline
% Only a few pages
% - Field of research
% - Goals and objectives
% - Significance of the project
% 2.3. Work plan
% \end{alltt}


\section*{Adaptive Disk Storage for Interaction Graphs}

\section{Summary}

Graph databases are becoming increasingly popular for applications in the world-wide web, social networks, and telecommunications.  An interaction graph is an append-only graph, where new edges and vertices are added as time progresses. A good example of an interaction graph is Twitter, where users represent vertices, and edges are mentions of other users

%
In an interaction graph database organized as blocks of temporal neighborlists
(as in Gedik et al.~\cite{gedik14}), it is important to store the edge and vertex
properties locally. For  instance, if the edge properties are kept away in a
relational table, there will be almost no benefit to the locality
optimizations performed for block organization (discussed in Gedik et al.~\cite{gedik14}, as we would have to go back and forth between the disk blocks to
access the edge attributes.
%

On the other hand, putting all the edge attributes into the disk blocks
containing the graph structure is expected to cause significant overhead when
only a few of these attributes are read. This is somewhat similar to the
problem with row-oriented databases, where the entire row needs to be accessed
from the disk despite the query needing only a small fraction of it.
Unfortunately, there is no clear correspondence to a column-oriented database
layout for the graph databases.
%

Recall that interaction graphs are temporal. As such, the co-access
correlations for the attributes can be different for different temporal
regions. It might also  be unknown at the insertion time and may be discovered
later depending on the workload. This points to the need for adaptively
optimizing the layout (somewhat similar to the H2O~\cite{alagiannis14}).
%

I imagine a solution to this problem, which I name the 'rail layout'. The idea
is to start with large blocks that contain the entire data. As we learn about
the access properties for different time regions, we might start splitting
such blocks into smaller blocks that run parallel to each other, almost like
having two or more graph databases for certain time regions, each containing a
 different subset of the attributes, but with a link between them in case a
query needs to access both. Some attributes can be replicated as well.
More details to follow about all this...


\section{Project outline}

\subsection{Field of research}

Graph Database work:
\begin{alltt}\scriptsize
- Googleâ€™s Pregel~\cite{malewicz10}
- Apache Giraph~\cite{giraph}
- GPS~\cite{salihoglu13}
- Trinity~\cite{shao13}
- PowerGraph~\cite{gonzalez12}
- Prabhakaran et al.~\cite{prabhakaran12}
- X-Stream~\cite{roy13}
- Xie et al. ~\cite{xie13}
- Neo4j ~\cite{neo4j}
- HyperGraphDB ~\cite{hypergraphdb}
- Tao (Facebook)~\cite{venkataramani12}
- Kineograph~\cite{cheng12}
-  Titan ~\cite{titan}
\end{alltt} 

Adaptive storage:
\begin{alltt}\scriptsize
H2O: A Hands-free Adaptive Store~cite{alagiannis14}
http://stratos.seas.harvard.edu/publications/h2o-hands-free-adaptive-store
\end{alltt} 


\subsection{Goals and objectives}
\subsection{Significance of the project}

\section{Work plan}

The work described in this proposal consists of five threads of activity.
\begin{itemize}
\item \emph{Define cost model}
\item \emph{Design partitioning algorithm}
\item \emph{Implement prototype}
\item \emph{Micro-benchmarks}
\item \emph{Real work applications}
\end{itemize}


{\footnotesize
\bibliographystyle{abbrv}
\balance
\bibliography{main}
}
 
\end{document}
